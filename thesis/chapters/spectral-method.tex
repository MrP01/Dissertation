\chapter{Spectral Method}
\label{chap:spectral-method}

% \section{Content}
% \input{chapters/out/Spectral Method.md.tex}

In this chapter we will construct a spectral method in the basis of Jacobi polynomials to explore the solution of equilibrium distributions $\rho(\vec{x})$.
Starting from a many-body system and considering the continuous limit as $N_p \goesto \infty$, in \Cref{chap:particle-interaction-theory} we have already established the governing equation of the particle density distribution $\rho(\vec{x})$ in such a system.

Can we put together a numerical method to solve for the equilibrium distribution (cf. \Cref{def:equilibrium-measure})?
Let us consider the problem from the bottom up and start from the solution:
The basic idea behind spectral methods is to assume a solution $\rho(\vec{x})$ of the form
$$\rho(\vec{x}) = \sum_{k=0}^{N-1} \rho_k \varphi_k(\vec{x})\,,\quad \rho_k \in \R, \varphi_k: \R^d \mapsto \R\,,\quad k = 0, ..., N-1\,,$$
with $N$ coefficients $\vec{\rho} := \left(\rho_0, ..., \rho_{N-1}\right)^T$ multiplying $N$ basis functions $\varphi_k$.

\section{Orthogonal Polynomials forming a Basis}
The following section will introduce a few necessary objects and tools to understand the basis of functions we are working with to construct the spectral method, the basis of Jacobi polynomials.

We start with the Pochhammer symbol, another name for the \textit{rising factorial}, an unusual notation for a function but standard in the context of the special functions that will be introduced on top of it.
\input{chapters/bits/rising-factorial.tex}

As a second prerequisite, we introduce closely intertwined beta- and gamma-functions.
\input{chapters/bits/gamma-function.tex}
\input{chapters/bits/beta-function.tex}

In order to efficiently construct a spectral method, we need an orthogonal basis.
\input{chapters/bits/orthogonal-polynomials.tex}
\input{chapters/bits/three-term-recurrence-relationship.tex}

Using the Pochhammer symbol introduced in \Cref{def:rising-factorial}, we can now define the generalised hypergeometric series ${}_pF_q$ (cf. \Cref{def:generalised-hypergeometric-series}) and a special case of it, the Gaussian hypergeometric function (cf. \Cref{def:gaussian-hypergeometric-function}).
\input{chapters/bits/generalised-hypergeometric-series.tex}
\input{chapters/bits/gaussian-hypergeometric-function.tex}

The Jacobi polynomials are then defined from ${}_2F_1$ as follows:
\input{chapters/bits/jacobi-polynomials.tex}
\input{chapters/bits/gegenbauer-polynomials.tex}
\input{chapters/bits/chebyshev-polynomials.tex}

In order to obtain a recurrence relationship between the coefficients later, we make use of the Jacobi matrix (cf. \Cref{def:jacobi-matrix}).
\input{chapters/bits/jacobi-matrix.tex}

Finally, now that we have established the basis functions, we can write down an ansatz for the solution of \hyperref[sec:the-problem]{the problem}.
\input{chapters/bits/ansatz.tex}

The spectral method can then be written as a linear system involving a matrix (operator).
\input{chapters/bits/operator.tex}
\input{chapters/bits/theorem216.tex}

\section{Derivation of Operator}
\input{chapters/bits/derivation-of-operator-matrix.tex}

\begin{figure}[H]
  \centering
  \label{fig:attractive-repulsive}
  \includegraphics[width=\linewidth]{results/attrep/attractive-repulsive-operators.pdf}
  \caption[Attractive and repulsive operators.]{The attractive and repulsive operators (matrices) as given in \Cref{def:operator}, the matrix values are shown in a $\log_{10}$ color scale. Due to the choice of basis, the attractive operator is exactly banded. The repulsive parameter is only approximately banded, which the spy plots effectively demonstrate.}
\end{figure}

The bandedness of the attractive operator is due to the three-term recurrence relationship of the Jacobi polynomial basis.
% TODO.. explain

For the attractive-repulsive interaction potential, the full operator is given by
\begin{equation}
  Q_{\alpha, \beta} := \frac{R^\alpha}{\alpha} Q^\alpha - \frac{R^\beta}{\beta} Q^\beta
  \label{eq:full-attrep-operator}
\end{equation}
for some interval radius $R \in \R^+$, usually chosen as the smallest possible $R$ such that $\supp(\rho) \subseteq [-R, R]$.

\begin{figure}[H]
  \centering
  \label{fig:attrep-operator}
  \includegraphics[width=0.5\linewidth]{results/attrep/full-operator.pdf}
  \caption[Combination of the attractive-repulsive operators]{Spy plot of $Q_{\alpha, \beta}$, the combination of the attractive-repulsive operators. Inverting this operator and applying it to $(1, 0, ..., 0)^T \in \R^N$ will yield the unnormalised coefficients $\rho_k$ of the solution expansion given in \Cref{def:ansatz}.}
\end{figure}

\section{Results}
\begin{figure}[H]
  \centering
  \label{fig:solution-increasing-order}
  \includegraphics[width=0.8\linewidth]{results/attrep/solution-increasing-order.pdf}
  \caption[Solutions of increasing orders]{Particle density distribution function solutions $\rho$ of increasing order $N$ to the attractive-repulsive problem with interaction potential $K_{alpha, \beta}(r)$, $\alpha = 2.5$ and $\beta = 1.2$. Reflected along the y-axis for better visibility of the domain.}
\end{figure}

\section{Outer Optimisation Routine}
\begin{figure}[H]
  \centering
  \label{fig:outer-optimisation}
  \includegraphics[width=0.8\linewidth]{results/known-analytic/outer-optimisation.pdf}
  \caption[Outer Optimisation Routine]{The total potential $U$ as a function of the support radius $R$. This is the goal function minimised by the outer optimisation routine.}
\end{figure}

Note that using this setup, the operators themselves do not need to be recomputed upon a change in $R$ (cf. \Cref{eq:full-attrep-operator}).
The provided implementation uses \gls{lru} caching to automatically store operators for a given parameter set and order $N$.

\section{Comparison with Analytic Solutions}
As introduced in \Cref{sec:analytical-solutions}, there are some analytical solutions available which allow us to perform some further analysis of the numerical method in these special cases.

\begin{figure}[H]
  \centering
  \label{fig:analytic-solution}
  \includegraphics[width=\linewidth]{results/known-analytic/analytic-solution.pdf}
  \caption[Comparison with analytical solutions and error]{
    The analytic solution $\rho(x)$ given in \Cref{eq:analytical-solution-alpha-equal-2} compared to the (spectral method) solutions of different order $N$.
    The ``arches'' occur as a result of the roots of $\rho(x) - \rho_N(x)$, their number approximately equals the order $N$ (a polynomial of degree $N$ has $N$ roots).
  }
\end{figure}

\input{chapters/bits/spectral-convergence.tex}

\begin{figure}[H]
  \centering
  \label{fig:convergence-to-analytic}
  \includegraphics[width=0.8\linewidth]{results/known-analytic/convergence-to-analytic.pdf}
  \caption[Convergence to analytic solution]{Convergence of the numerical solution to the known analytic solution (cf. \Cref{eq:analytical-solution-alpha-equal-2}) in a special case where it is known, squared error plotted as a function of the highest order in the expansion $N$.}
\end{figure}

\section{Discussion}
\begin{figure}[H]
  \centering
  \label{fig:convergence}
  \includegraphics[width=0.8\linewidth]{results/attrep/convergence.pdf}
  \caption[Step-by-step convergence of solutions compared to order 24]{Step-by-step convergence of numerical solutions $\rho_N(x)$ as compared to $\rho_{24}(x)$, visualised using the squared error of the pointwise evaluation of both functions in $200$ points.}
\end{figure}

\begin{figure}[H]
  \centering
  \label{fig:spatial-energy-dependence}
  \includegraphics[width=0.7\linewidth]{results/attrep/energy-dependence-on-r.pdf}
  \caption[Spatial energy dependence on $r$]{Plot of the spatial energy dependence on $r$, for different values of the domain support radius $R$. As one can see, they are constant and this figure is only present as visual proof to increase our confidence in the construction of the spectral method.}
\end{figure}

\begin{figure}[H]
  \centering
  \label{fig:varying-parameters}
  \includegraphics[width=0.9\linewidth]{results/attrep/varying-parameters.pdf}
  \caption[Varying parameters in the solver]{
    Varying different parameters in the solver to demonstrate their effect.
    See also, \Cref{fig:varying-R-solutions}.
  }
\end{figure}

\begin{figure}[H]
  \centering
  \label{fig:bump-solutions}
  \includegraphics[width=0.6\linewidth]{results/bump/solution-increasing-order}
  \caption[Bump parameter solutions]{Solutions with bump parameters.}
\end{figure}
